"""
Задание 1.

Вам нужно взять 5 любых скриптов, написанных ВАМИ в рамках работы над ДЗ
курсов Алгоритмы и Основы Python

На каждый скрипт нужно два решения - исходное и оптимизированное.

Вы берете исходное, пишете что это за задание и с какого оно курса.
Далее выполняете профилирование скрипта средствами memory_profiler

Вы оптимизируете исходное решение.
Далее выполняете профилирование скрипта средствами memory_profiler

Вам нужно написать аналитику, что вы сделали для оптимизации памяти и
чего добились.


ВНИМАНИЕ:
1) скрипты для оптимизации нужно брать только из сделанных вами ДЗ
курсов Алгоритмы и Основы
2) нельзя дублировать, коды, показанные на уроке
3) для каждого из 5 скриптов у вас отдельный файл, в нем должна быть версия до
и версия после оптимизации
4) желательно выбрать те скрипты, где есть что оптимизировать и не брать те,
где с памятью и так все в порядке
5) не нужно писать преподавателю '''я не могу найти что оптимизировать''', это
отговорки. Примеров оптимизации мы перечислили много: переход с массивов на
генераторы, numpy, использование слотов, применение del, сериализация и т.д.

Это файл для первого скрипта
"""

"""
Основы, урок 5, задание 5
Представлен список чисел. Определить элементы списка, не имеющие повторений. 
Сформировать из этих элементов список с сохранением порядка их следования в исходном списке,

Для оптимизации удалила словарь, в котором собирала промежуточные подсчёты чисел

До оптимизации:
Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    67     19.7 MiB     19.7 MiB           1   @profile
    68                                         def get_uniq_numbers(src: list):
    69     19.7 MiB      0.0 MiB           1       dict_nums = {}
    70     19.7 MiB      0.0 MiB         501       for x in src:
    71     19.7 MiB      0.0 MiB         500           dict_nums[x] = dict_nums.get(x, 0) + 1  # считаем в значениях количество повторов числа по по ключу числа
    72     19.7 MiB      0.0 MiB         503       new_list = [x for x in src if dict_nums[x] == 1] # формируем список из ключей, в которых значение == 1
    73                                         
    74     19.7 MiB      0.0 MiB           1       return new_list

после оптимизации:
Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    76     19.7 MiB     19.7 MiB           1   @profile
    77                                         def get_uniq_numbers_1(src: list):
    78     19.7 MiB      0.0 MiB           1       dict_nums = {}
    79     19.7 MiB      0.0 MiB         501       for x in src:
    80     19.7 MiB      0.0 MiB         500           dict_nums[x] = dict_nums.get(x, 0) + 1  # считаем в значениях количество повторов числа по по ключу числа
    81     19.7 MiB      0.0 MiB         503       new_list = [x for x in src if dict_nums[x] == 1] # формируем список из ключей, в которых значение == 1
    82     19.7 MiB      0.0 MiB           1       del dict_nums
    83     19.7 MiB      0.0 MiB           1       return new_list

Ну, видимо, не так уж нам мешал этот словарь
Имеет смысл только на каких-то больших объёмах, при увеличении списка с 500 элементов до 50000
но и то, не особо

до оптимизации:
Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    65     21.7 MiB     21.7 MiB           1   @profile
    66                                         def get_uniq_numbers(src: list):
    67     21.7 MiB      0.0 MiB           1       dict_nums = {}
    68     22.1 MiB      0.0 MiB       50001       for x in src:
    69     22.1 MiB      0.4 MiB       50000           dict_nums[x] = dict_nums.get(x, 0) + 1  # считаем в значениях количество повторов числа по по ключу числа
    70     22.1 MiB      0.0 MiB       50003       new_list = [x for x in src if dict_nums[x] == 1] # формируем список из ключей, в которых значение == 1
    71                                         
    72     22.1 MiB      0.0 MiB           1       return new_list

после оптимизации
Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    74     21.8 MiB     21.8 MiB           1   @profile
    75                                         def get_uniq_numbers_1(src: list):
    76     21.8 MiB      0.0 MiB           1       dict_nums = {}
    77     22.1 MiB      0.0 MiB       50001       for x in src:
    78     22.1 MiB      0.3 MiB       50000           dict_nums[x] = dict_nums.get(x, 0) + 1  # считаем в значениях количество повторов числа по по ключу числа
    79     22.1 MiB      0.0 MiB       50003       new_list = [x for x in src if dict_nums[x] == 1] # формируем список из ключей, в которых значение == 1
    80     21.9 MiB     -0.2 MiB           1       del dict_nums
    81     21.9 MiB      0.0 MiB           1       return new_list
"""
from memory_profiler import profile
from random import randint


@profile
def get_uniq_numbers(src: list):
    dict_nums = {}
    for x in src:
        dict_nums[x] = dict_nums.get(x, 0) + 1  # считаем в значениях количество повторов числа по по ключу числа
    new_list = [x for x in src if dict_nums[x] == 1] # формируем список из ключей, в которых значение == 1

    return new_list

@profile
def get_uniq_numbers_1(src: list):
    dict_nums = {}
    for x in src:
        dict_nums[x] = dict_nums.get(x, 0) + 1  # считаем в значениях количество повторов числа по по ключу числа
    new_list = [x for x in src if dict_nums[x] == 1] # формируем список из ключей, в которых значение == 1
    del dict_nums
    return new_list


# src = [2, 2, 2, 7, 23, 1, 44, 44, 3, 2, 10, 7, 4, 11]
# src = [randint(0,100) for i in range(500)]
# src = [randint(0,10000) for i in range(50000)]
print(get_uniq_numbers_(src))